@inproceedings{Bazin2007,
abstract = {Nowadays, robotic systems are more and more equipped with catadioptric cameras. However several problems associated to catadioptric vision have been studied only slightly. Especially algorithms for detecting rectangles in catadioptric images have not yet been developed whereas it is required in diverse applications such as building extraction in aerial images. We show that working in the equivalent sphere provides an appropriate framework to detect lines, parallelism, orthogonality and therefore rectangles. Finally, we present experimental results on synthesized and real data.},
author = {Bazin, Jean Charles and Kweon, Inso and Demonceaux, Cedric and Vasseur, Pascal},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2007.4409208},
file = {:home/a/Desktop/04409208.pdf:pdf},
isbn = {978-1-4244-1630-1},
issn = {15505499},
title = {{Rectangle extraction in catadioptric images}},
year = {2007}
}
@article{Bhaskar2010,
abstract = {We describe and compare methods for detecting rectangles in images using Hough and Radon transforms. Locating rectangles in a new image involves an alternating scheme of transform peak extraction and peak filtering. During the step of peak extraction, we apply the hough/radon transform on the target image and extract peaks (corresponding to line segments) from the transformed image. We filter these peaks based on certain geometric constraints in the transform and spatial constraints on the coordinate (or image) domain such that every set of 4 filtered peaks correspond to a rectangle in the image. We explore the effect of model parameters on system performance and show that the proposed methods achieves good accuracy for rectangle detection on several synthetic and real datasets.},
author = {Bhaskar, H and Werghi, N and {Al Mansoori}, Saeed},
file = {:home/a/Desktop/05712096.pdf:pdf},
journal = {Audio, Transactions of the IRE Professional Group on},
keywords = {aerial im-,constraints,hough,licence plate,radon,rectangle detection,spatial,transform domain},
pages = {1--7},
title = {{Combined spatial and transform domain analysis for rectangle detection}},
year = {2010}
}
@inproceedings{Bryson2007,
abstract = {In this paper we demonstrate a co-operative path-planning algorithm for multi-vehicle simultaneous localisation and mapping (SLAM) that uses information-based measures to maximize the accuracy of a feature map which is constructed from terrain observation made by each vehicle. The SLAM algorithm is distributed amongst the vehicles where each vehicle shares locally built map information via a central communications node. This information is used to assist in localisation which in turn increases the accuracy of the map information each vehicle provides. Each vehicle communicates to the central node potential trajectories it can take and the associated map information it will provide. The central communications node then co-ordinates the actions of each platform such as to maximise the accuracy of the globally constructed map. The vehicles each perform SLAM using a combination of on-board inertial sensors and an on-board terrain sensor. Results are presented using a 6-DoF simulation of several UAVs over an initially unexplored terrain.},
author = {Bryson, Mitch and Sukkarieh, Salah},
booktitle = {2007 IEEE Aerospace Conference},
doi = {10.1109/AERO.2007.352850},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bryson, Sukkarieh - 2007 - Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments.pdf:pdf},
isbn = {1-4244-0524-6},
issn = {1095-323X},
keywords = {Autonomous Vehicles,Mapping,Multi-Vehicle Co-operation.,Navigation,SLAM},
pages = {1--12},
title = {{Co-operative Localisation and Mapping for Multiple UAVs in Unknown Environments}},
year = {2007}
}
@inproceedings{Cadena2015,
abstract = {We propose a semantic scene understanding system that is suitable for real robotic operations. The system solves different tasks (semantic segmentation and object detections) in an opportunistic and distributed fashion but still allows communication between modules to improve their respective performances. We propose the use of the semantic space to improve specific out-of-the-box object detectors and an update model to take the evidence from different detection into account in the semantic segmentation process. Our proposal is evaluated with the KITTI dataset, on the object detection benchmark and on five different sequences manually annotated for the semantic segmentation task, demonstrating the efficacy of our approach.},
author = {Cadena, Cesar and Dick, Anthony and Reid, Ian D},
booktitle = {Robotics and Automation (ICRA), 2015 IEEE International Conference on},
doi = {10.1109/ICRA.2015.7139874},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cadena, Dick, Reid - 2015 - A Fast , Modular Scene Understanding System using Context-Aware Object Detection.pdf:pdf},
isbn = {VO -},
keywords = {Benchmark testing,Context,Detectors,Object detection,Robots,Semantics,Training,context-aware object detection,control engineering computing,image segmentation,modular scene understanding system,object detection,object detections,out-of-the-box object detectors,robotic operations,robots,semantic scene understanding system,semantic segmentation process,semantic segmentation task,ubiquitous computing},
pages = {4859--4866},
title = {{A fast, modular scene understanding system using context-aware object detection}},
year = {2015}
}
@inproceedings{Choudhary2015,
abstract = {In this paper, we present an information-based approach to select a reduced number of landmarks and poses for a robot to localize itself and simultaneously build an accurate map. We develop an information theoretic algorithm to efficiently reduce the number of landmarks and poses in a SLAM estimate without compromising the accuracy of the estimated trajectory. We also propose an incremental version of the reduction algorithm which can be used in SLAM framework resulting in information based reduced landmark SLAM. The results of reduced landmark based SLAM algorithm are shown on Victoria park dataset and a Synthetic dataset and are compared with standard graph SLAM (SAM [6]) algorithm. We demonstrate a reduction of 40-50{\%} in the number of landmarks and around 55{\%} in the number of poses with minimal estimation error as compared to standard SLAM algorithm.},
author = {Choudhary, Siddharth and Indelman, Vadim and Christensen, Henrik I and Dellaert, Frank},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2015.7139839},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choudhary et al. - 2015 - Information-based Reduced Landmark SLAM.pdf:pdf},
isbn = {9781479969227},
issn = {10504729},
number = {June},
pages = {4620--4627},
title = {{Information-based reduced landmark SLAM}},
volume = {2015-June},
year = {2015}
}
@article{Cummins2011,
abstract = {The paper discusses robot navigation from biological inspiration. The authors sought to build a model of the rodent brain that is suitable for practical robot navigation. The core model, dubbed RatSLAM, has been demonstrated to have exactly the same advantages described earlier: it can build, maintain, and use maps simultaneously over extended periods of time and can construct maps of large and complex areas from very weak geometric information. The work contrasts with other efforts to embody models of rat brains in robots. The article describes the key elements of the known biology of the rat brain in relation to navigation and how the RatSLAM model captures the ideas from biology in a fashion suitable for implementation on a robotic platform. The paper then outline RatSLAM's performance in two difficult robot navigation challenges, demonstrating how a cognitive robotics approach to navigation can produce results that rival other state of the art approaches in robotics.},
archivePrefix = {arXiv},
arxivId = {0010-0285/97},
author = {Cummins, M. and Newman, P.},
doi = {10.1177/0278364910385483},
eprint = {97},
isbn = {0010-0285 (Print)$\backslash$r0010-0285 (Linking)},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {Appearance-based localization,Bayes methods,Bayesian filtering framework,Cameras,Cognitive mapping,Databases,FAB-MAP,FABMAP,Fingerprints of places,Generalization,Humans,Image recognition,Image representation,Models,Multi-modal perception,Neurorobotics,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Psychological,Recognition,Recognition (Psychology),Robotics,Robots,SLAM,Social Environment,Space Perception,Space Perception: physiology,Spatial representations,Stimulus,Stimulus: physiology,Topological navigation,Urban areas,Visual,Visual Fields,Visual Fields: physiology,Vocabulary,appearance based localization,appearance-based localization and mapping,appearance-based navigation,autonomous robotic systems,biologically inspired,biologically inspired robots,computer vision,energy spectrum,fab-map,filtering theory,gist descriptor,global descriptors,image features,image representation,invariant robust feature,learning and adaptive systems,localization,location recognition,loop detection,natural images,omnidirectional images,panoramic datasets,panoramic gist descriptor,persistent navigation and mapping,principal components,ratslam,recognition,robot navigation,robot vision,robotics,scene recognition,slam,spatial layout,topological slam,urban environment localization,vision based topological localization},
number = {9},
pages = {1100--1123},
pmid = {396576},
primaryClass = {0010-0285},
title = {{Appearance-only SLAM at large scale with FAB-MAP 2.0}},
volume = {30},
year = {2011}
}
@article{Davey2007,
author = {Davey, Samuel J.},
doi = {10.1109/TRO.2007.892235},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davey - 2007 - Simultaneous localization and map building using the probabilistic multi-hypothesis tracker.pdf:pdf},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Data association,Map building,Navigation,Probabilistic multi-hypothesis tracker (PMHT),Simultaneous localization and map building (SLAM)},
number = {2},
pages = {271--280},
title = {{Simultaneous localization and map building using the probabilistic multi-hypothesis tracker}},
volume = {23},
year = {2007}
}
@article{Davison2007,
author = {Davison, Andrew J and Reid, Ian D and Molton, Nicholas D and Stasse, Olivier},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {6},
pages = {1052--1067},
publisher = {IEEE},
title = {{MonoSLAM: Real-time single camera SLAM}},
volume = {29},
year = {2007}
}
@article{Dellaert2006,
abstract = {Solving the SLAM problem is one way to enable a robot to explore, map, and navigate in a previously unknown environment. We investigate smoothing approaches as a viable alternative to extended Kalman filter-based solutions to the problem. In particular, we look at approaches that factorize either the associated information matrix or the measurement Jacobian into square root form. Such techniques have several significant advantages over the EKF: they are faster yet exact, they can be used in either batch or incremental mode, are better equipped to deal with non-linear process and measurement models, and yield the entire robot trajectory, at lower cost for a large class of SLAM problems. In addition, in an indirect but dramatic way, column ordering heuristics automatically exploit the locality inherent in the geographic nature of the SLAM problem. In this paper we present the theory underlying these methods, along with an interpretation of factorization in terms of the graphical model associated with the SLAM problem. We present both simulation results and actual SLAM experiments in large-scale environments that underscore the potential of these methods as an alternative to EKF-based approaches. 1},
archivePrefix = {arXiv},
arxivId = {there is not},
author = {Dellaert, F. and Kaess, M.},
doi = {10.1177/0278364906072768},
eprint = {there is not},
isbn = {0278364906072},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {graphical models,mobile robots,slam},
number = {12},
pages = {1181--1203},
pmid = {1638022},
title = {{Square Root SAM: Simultaneous Localization and Mapping via Square Root Information Smoothing}},
volume = {25},
year = {2006}
}
@inproceedings{Dissanayake2000,
abstract = {The theoretical basis of the solution to the simultaneous localisation and map building (SLAM) problem where an autonomous vehicle starts in an unknown location in an unknown environment and then incrementally build a map of landmarks present in this environment while simultaneously using this map to compute absolute vehicle location is well understood. Although a number of SLAM implementations have appeared in the literature, the need to maintain the knowledge of the relative relationships between all the landmark location estimates contained in the map makes SLAM computationally intractable in implementations containing more than few tens of landmarks. In this paper, the theoretical basis and a practical implementation of a computationally efficient solution to SLAM is presented. The paper shows that it is indeed possible to remove a large percentage of the landmarks from the map without making the map-building process statistically inconsistent. Furthermore, it is shown that the efficiency of the SLAM can be maintained by judicious selection of landmarks, to be preserved in the map, based on their information content},
author = {Dissanayake, Gamini and Durrant-whyte, Hugh and Bailey, Tim},
booktitle = {Robotics and Automation, 2000. Proceedings. ICRA '00. IEEE International Conference on},
doi = {10.1109/ROBOT.2000.844732},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dissanayake, Durrant-whyte, Bailey - 2000 - A com-putationally efficient solution to the simultaneous localisa- tion and map building (s.pdf:pdf},
isbn = {0780358864},
keywords = {SLAM problem,computational complexity,computationally efficient solution,estimation theory,landmark information content,localisation problem,map building problem,mobile robots,position measurement},
number = {April 2000},
pages = {1009 -- 1014 vol.2},
title = {{A computationally efficient solution to the simultaneous localisa- tion and map building (slam) problem.}},
year = {2000}
}
@article{Durrant2006,
author = {Durrant-whyte, B Y Hugh and Bailey, Tim I M and Cheeseman, Peter and Crowley, Jim and Durrant-, Hugh and Durrant-Whyte, Hugh},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Durrant-whyte et al. - 2006 - Simultaneous Localization and Mapping Part I.pdf:pdf},
journal = {Robotics {\&} Automation Magazine, IEEE},
number = {2},
pages = {99--110},
publisher = {IEEE},
title = {{Simultaneous localization and mapping: part I}},
volume = {13},
year = {2006}
}
@inproceedings{Eade2006,
author = {Eade, E. and Drummond, T.},
booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1 (CVPR'06)},
doi = {10.1109/CVPR.2006.263},
isbn = {0-7695-2597-0},
pages = {469--476},
publisher = {Ieee},
title = {{Scalable Monocular SLAM}},
volume = {1},
year = {2006}
}
@inproceedings{Engel2014,
abstract = {We propose a direct (feature-less) monocular SLAM algorithm which, in contrast to current state-of-the-art regarding direct meth- ods, allows to build large-scale, consistent maps of the environment. Along with highly accurate pose estimation based on direct image alignment, the 3D environment is reconstructed in real-time as pose-graph of keyframes with associated semi-dense depth maps. These are obtained by filtering over a large number of pixelwise small-baseline stereo comparisons. The explicitly scale-drift aware formulation allows the approach to operate on challenging sequences including large variations in scene scale. Major enablers are two key novelties: (1) a novel direct tracking method which operates on sim(3), thereby explicitly detecting scale-drift, and (2) an elegant probabilistic solution to include the effect of noisy depth values into tracking. The resulting direct monocular SLAM system runs in real-time on a CPU.},
author = {Engel, Jakob and Sch, Thomas and Cremers, Daniel},
booktitle = {Computer Vision–ECCV 2014},
doi = {10.1007/978-3-319-10605-2_54},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engel, Sch, Cremers - 2014 - LSD-SLAM Large-Scale Direct Monocular SLAM.pdf:pdf},
isbn = {978-3-319-10604-5},
issn = {16113349},
pages = {834--849},
publisher = {Springer International Publishing},
title = {{LSD-SLAM: Large-Scale Direct Monocular SLAM}},
year = {2014}
}
@inproceedings{Forster2014b,
abstract = {We propose a semi-direct monocular visual odometry algorithm that is precise, robust, and faster than current state-of-the-art methods. The semi-direct approach eliminates the need of costly feature extraction and robust matching techniques for motion estimation. Our algorithm operates directly on pixel intensities, which results in subpixel precision at high frame-rates. A probabilistic mapping method that explicitly models outlier measurements is used to estimate 3D points, which results in fewer outliers and more reliable points. Precise and high frame-rate motion estimation brings increased robustness in scenes of little, repetitive, and high-frequency texture. The algorithm is applied to micro-aerial-vehicle state- estimation in GPS-denied environments and runs at 55 frames per second on the onboard embedded computer and at more than 300 frames per second on a consumer laptop. We call our approach SVO (Semi-direct Visual Odometry) and release our implementation as open-source software.},
author = {Forster, Christian and Pizzoli, Matia and Scaramuzza, Davide},
booktitle = {IEEE Int. Conference on Robotics and Automation (ICRA)},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forster, Pizzoli, Scaramuzza - 2014 - SVO Fast Semi-Direct Monocular Visual Odometry.pdf:pdf},
isbn = {9781479936847},
pmid = {6576973927449638915},
title = {{SVO : Fast Semi-Direct Monocular Visual Odometry}},
year = {2014}
}
@article{Guerrero2008,
abstract = {This paper addresses the robot and landmark localization problem from bearing-only data in three views, simultaneously to the robust association of this data. The localization algorithm is based on the 1-D trifocal tensor, which relates linearly the observed data and the robot localization parameters. The aim of this work is to bring this useful geometric construction from computer vision closer to robotic applications. One contribution is the evaluation of two linear approaches of estimating the 1-D tensor: the commonly used approach that needs seven bearing-only correspondences and another one that uses only five correspondences plus two calibration constraints. The results in this paper show that the inclusion of these constraints provides a simpler and faster solution and better estimation of robot and landmark locations in the presence of noise. Moreover, a new method that makes use of scene planes and requires only four correspondences is presented. This proposal improves the performance of the two previously mentioned methods in typical man-made scenarios with dominant planes, while it gives similar results in other cases. The three methods are evaluated with simulation tests as well as with experiments that perform automatic real data matching in conventional and omnidirectional images. The results show sufficient accuracy and stability to be used in robotic tasks such as navigation, global localization or initialization of simultaneous localization and mapping (SLAM) algorithms.},
author = {Guerrero, J. J. and Murillo, a. C. and Sag{\"{u}}{\'{e}}s, C.},
doi = {10.1109/TRO.2008.918043},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guerrero, Murillo, Sag{\"{u}}{\'{e}}s - 2008 - Localization and matching using the planar trifocal tensor with bearing-only data.pdf:pdf},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {1-D trifocal tensor,Bearing-only data,Global localization,Robot vision,Robust matching,SLAM initialization},
number = {2},
pages = {494--501},
title = {{Localization and matching using the planar trifocal tensor with bearing-only data}},
volume = {24},
year = {2008}
}
@article{Han2009,
abstract = {This paper presents a simple attribute graph grammar as a generative representation for made-made scenes, such as buildings, hallways, kitchens, and living rooms, and studies an effective top-down/bottom-up inference algorithm for parsing images in the process of maximizing a Bayesian posterior probability or equivalently minimizing a description length (MDL). Given an input image, the inference algorithm computes (or constructs) a parse graph, which includes a parse tree for the hierarchical decomposition and a number of spatial constraints. In the inference algorithm, the bottom-up step detects an excessive number of rectangles as weighted candidates, which are sorted in certain order and activate top-down predictions of occluded or missing components through the grammar rules. In the experiment, we show that the grammar and top-down inference can largely improve the performance of bottom-up detection.},
author = {Han, Feng and Zhu, Song Chun},
doi = {10.1109/TPAMI.2008.65},
isbn = {076952334X},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Algorithms,Attribute graph grammar,Bottom-up/top-down,Generative model,Image parsing,Pattern analysis,Primal sketch,Statistical},
number = {1},
pages = {59--73},
pmid = {19029546},
title = {{Bottom-up/top-down image parsing with attribute grammar}},
volume = {31},
year = {2009}
}
@book{Hartley2003,
abstract = {A basic problem in computer vision is to understand the structure of a real world scene given several images of it. Techniques for solving this problem are taken from projective geometry and photogrammetry. Here, the authors cover the geometric principles and their algebraic representation in terms of camera projection matrices, the fundamental matrix and the trifocal tensor. The theory and methods of computation of these entities are discussed with real examples, as is their use in the reconstruction of scenes from multiple images. The new edition features an extended introduction covering the key ideas in the book (which itself has been updated with additional examples and appendices) and significant new results which have appeared since the first edition. Comprehensive background material is provided, so readers familiar with linear algebra and basic numerical methods can understand the projective geometry and estimation algorithms presented, and implement the algorithms directly from the book.},
author = {Hartley, Richard and Zisserman, Andrew},
isbn = {0521540518},
title = {{Multiple View Geometry in Computer Vision}},
url = {https://books.google.com/books?hl=ko{\&}lr={\&}id=si3R3Pfa98QC{\&}pgis=1},
year = {2003}
}
@inproceedings{Jeong2005,
abstract = { We propose a fast and robust CV-SLAM (ceiling vision-based simultaneous localization and mapping) technique using a single ceiling vision sensor. The proposed algorithm is suitable for system that demands very high localization accuracy such as an intelligent robot vacuum cleaner. A single camera looking upward direction (called ceiling vision system) is mounted on the robot, and salient image features are detected and tracked through the image sequence. Compared with the conventional frontal view systems, the ceiling vision has advantage in tracking, since it involves only rotation and affine transform without scale change. And, in this paper, we solve the rotation and affine transform problems using 3D gradient orientation estimation method and multi-view description of landmarks. By applying these methods to the solution for data association, we can reconstruct the 3D landmark map in real-time through the extend Kalman filter based SLAM framework. Furthermore, relocation problem is solved efficiently by using a wide base line matching between the reconstructed 3D map and a 2D ceiling image. Experimental results demonstrate the accuracy and robustness of the proposed algorithm in real environments.},
author = {Jeong, Woo Yeon and Lee, Kyoung Mu},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
doi = {10.1109/IROS.2005.1545443},
isbn = {0780389123},
keywords = {Ceiling vision,Data association,SLAM},
pages = {3070--3075},
title = {{CV-SLAM: A new ceiling vision-based SLAM technique}},
year = {2005}
}
@inproceedings{Jung2004,
abstract = {The problem of detecting rectangular structures in images arises in many applications, from building extraction in aerial images to particle detection in cryo-electron microscopy. This paper proposes a new technique for rectangle detection using a windowed Hough transform. Every pixel of the image is scanned, and a sliding window is used to compute the Hough transform of small regions of the image. Peaks of the Hough image (which correspond to line segments) are then extracted, and a rectangle is detected when four extracted peaks satisfy certain geometric conditions. Experimental results indicate that the proposed technique produced promising results for both synthetic and natural images.},
author = {Jung, Cl{\'{a}}udio Rosito and Schramm, Rodrigo},
booktitle = {Brazilian Symposium of Computer Graphic and Image Processing},
doi = {10.1109/SIBGRA.2004.1352951},
file = {:home/a/Desktop/1.pdf:pdf},
isbn = {0769522270},
issn = {15301834},
pages = {113--120},
title = {{Rectangle detection based on a windowed hough transform}},
year = {2004}
}
@inproceedings{Kaess2011,
abstract = {We present iSAM2, a fully incremental, graph-based version of incremental smoothing and mapping (iSAM). iSAM2 is based on a novel graphical model-based interpretation of incremental sparse matrix factorization methods, afforded by the recently introduced Bayes tree data structure. The original iSAM algorithm incrementally maintains the square root information matrix by applying matrix factorization updates. We analyze the matrix updates as simple editing operations on the Bayes tree and the conditional densities represented by its cliques. Based on that insight, we present a new method to incrementally change the variable ordering which has a large effect on efficiency. The efficiency and accuracy of the new method is based on fluid relinearization, the concept of selectively relinearizing variables as needed. This allows us to obtain a fully incremental algorithm without any need for periodic batch steps. We analyze the properties of the resulting algorithm in detail, and show on various real and simulated datasets that the iSAM2 algorithm compares favorably with other recent mapping algorithms in both quality and efficiency.},
author = {Kaess, Michael and Johannsson, Hordur and Roberts, Richard and Ila, Viorela and Leonard, John and Dellaert, Frank},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979641},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaess et al. - 2011 - ISAM2 Incremental smoothing and mapping with fluid relinearization and incremental variable reordering.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
pages = {3281--3288},
title = {{ISAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering}},
year = {2011}
}
@inproceedings{Kaess2007,
abstract = {We introduce incremental smoothing and mapping (iSAM), a novel approach to the problem of simultaneous localization and mapping (SLAM) that addresses the data association problem and allows real-time application in large-scale environments. We employ smoothing to obtain the complete trajectory and map without the need for any approximations, exploiting the natural sparsity of the smoothing information matrix. A QR-factorization of this information matrix is at the heart of our approach. It provides efficient access to the exact covariances as well as to conservative estimates that are used for online data association. It also allows recovery of the exact trajectory and map at any given time by back-substitution. Instead of refactoring in each step, we update the QR-factorization whenever a new measurement arrives. We analyze the effect of loops, and show how our approach extends to the non-linear case. Finally, we provide experimental validation of the overall non-linear algorithm based on the standard Victoria Park data set with unknown correspondences.},
author = {Kaess, Michael and Ranganathan, Ananth and Dellaert, Frank},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2007.363563},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaess, Ranganathan, Dellaert - 2007 - iSAM Fast incremental smoothing and mapping with efficient data association.pdf:pdf},
isbn = {1424406021},
issn = {10504729},
number = {April},
pages = {1670--1677},
title = {{iSAM: Fast incremental smoothing and mapping with efficient data association}},
year = {2007}
}
@inproceedings{Klein2007,
abstract = {This paper presents a method of estimating camera pose in an unknown scene. While this has previously been attempted by adapting SLAM algorithms developed for robotic exploration, we propose a system specifically designed to track a hand-held camera in a small AR workspace. We propose to split tracking and mapping into two separate tasks, processed in parallel threads on a dual-core computer: one thread deals with the task of robustly tracking erratic hand-held motion, while the other produces a 3D map of point features from previously observed video frames. This allows the use of computationally expensive batch optimisation techniques not usually associated with real-time operation: The result is a system that produces detailed maps with thousands of landmarks which can be tracked at frame-rate, with an accuracy and robustness rivalling that of state-of-the-art model-based systems.},
author = {Klein, Georg and Murray, David},
booktitle = {2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, ISMAR},
doi = {10.1109/ISMAR.2007.4538852},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klein, Murray - 2007 - Parallel tracking and mapping for small AR workspaces.pdf:pdf},
isbn = {9781424417506},
issn = {00472778},
title = {{Parallel tracking and mapping for small AR workspaces}},
year = {2007}
}
@inproceedings{Kummerle2011,
abstract = {Many popular problems in robotics and computer vision including various types of simultaneous localization and mapping (SLAM) or bundle adjustment (BA) can be phrased as least squares optimization of an error function that can be represented by a graph. This paper describes the general structure of such problems and presents g{\textless}sup{\textgreater}2{\textless}/sup{\textgreater}o, an open-source C++ framework for optimizing graph-based nonlinear error functions. Our system has been designed to be easily extensible to a wide range of problems and a new problem typically can be specified in a few lines of code. The current implementation provides solutions to several variants of SLAM and BA. We provide evaluations on a wide range of real-world and simulated datasets. The results demonstrate that while being general g{\textless}sup{\textgreater}2{\textless}/sup{\textgreater}o offers a performance comparable to implementations of state-of-the-art approaches for the specific problems.},
author = {K{\"{u}}mmerle, Rainer and Grisetti, Giorgio and Strasdat, Hauke and Konolige, Kurt and Burgard, Wolfram},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979949},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{u}}mmerle et al. - 2011 - G2o A general framework for graph optimization.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
pages = {3607--3613},
pmid = {5979949},
title = {{G2o: A general framework for graph optimization}},
year = {2011}
}
@inproceedings{Lategahn2011,
abstract = {Simultaneous Localization and Mapping (SLAM) and Visual SLAM (V-SLAM) in particular have been an active area of research lately. In V-SLAM the main focus is most often laid on the localization part of the problem allowing for a drift free motion estimate. To this end, a sparse set of landmarks is tracked and their position is estimated. However, this set of landmarks (rendering the map) is often too sparse for tasks in autonomous driving such as navigation, path planning, obstacle avoidance etc. Some methods keep the raw measurements for past robot poses to address the sparsity problem often resulting in a pose only SLAM akin to laser scanner SLAM. For the stereo case, this is however impractical due to the high noise of stereo reconstructed point clouds. In this paper we propose a dense stereo V-SLAM algorithm that estimates a dense 3D map representation which is more accurate than raw stereo measurements. Thereto, we run a sparse V-SLAM system, take the resulting pose estimates to compute a locally dense representation from dense stereo correspondences. This dense representation is expressed in local coordinate systems which are tracked as part of the SLAM estimate. This allows the dense part to be continuously updated. Our system is driven by visual odometry priors to achieve high robustness when tracking landmarks. Moreover, the sparse part of the SLAM system uses recently published sub mapping techniques to achieve constant runtime complexity most of the time. The improved accuracy over raw stereo measurements is shown in a Monte Carlo simulation. Finally, we demonstrate the feasibility of our method by presenting outdoor experiments of a car like robot.},
author = {Lategahn, Henning and Geiger, Andreas and Kitt, Bernd},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979711},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lategahn, Geiger, Kitt - 2011 - Visual SLAM for autonomous ground vehicles.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
pages = {1732--1737},
title = {{Visual SLAM for autonomous ground vehicles}},
year = {2011}
}
@inproceedings{Lee2012,
abstract = {Given a single image of a scene rectangle of an un- known aspect ratio and size, we present a method to reconstruct the projective structure and to find camera parameters including focal length, position, and orien- tation. First, we solve the special case when the center of a scene rectangle is projected to the image center. We formulate this problem with coupled line cameras and present the analytic solution for it. Then, by prefixing a simple preprocessing step, we solve the general case without the centering constraint. We also provides a determinant to tell if an image quadrilateral is a pro- jection of a rectangle. We demonstrate the performance of the proposed method with synthetic and real data.},
author = {Lee, Joo-Haeng},
booktitle = {Pattern Recognition (ICPR), 2012 21st International {\ldots}},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee - 2012 - Camera calibration from a single image based on coupled line cameras and rectangle constraint.pdf:pdf},
isbn = {9784990644109},
issn = {10514651},
keywords = {2D/3D Object Detection and Recognition,Motion,Scene Understanding,Tracking and Video Analysis},
number = {Icpr},
pages = {758--762},
title = {{Camera calibration from a single image based on coupled line cameras and rectangle constraint}},
year = {2012}
}
@article{Lee2013,
author = {Lee, Joo-Haeng},
doi = {10.4218/etrij.13.0213.0087},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee - 2013 - A New Solution for Projective Reconstruction Based on Coupled Line Cameras.pdf:pdf},
issn = {1225-6463},
journal = {ETRI Journal},
keywords = {camera calibration,coupled line cameras,diagonal parameterization,geometric computer vision,projective,reconstruction},
month = {oct},
number = {5},
pages = {939--942},
title = {{A New Solution for Projective Reconstruction Based on Coupled Line Cameras}},
volume = {35},
year = {2013}
}
@inproceedings{Lee2014,
abstract = {A new geometric framework, called generalized coupled line camera (GCLC), is proposed to derive an analytic solution to reconstruct an unknown scene quadrilateral and the relevant projective structure from a single or multiple image quadrilaterals. We extend the previous approach developed for rectangle to handle arbitrary scene quadrilaterals. First, we generalize a single line camera by removing the centering constraint that the principal axis should bisect a scene line. Then, we couple a pair of generalized line cameras to model a frustum with a quadrilateral base. Finally, we show that the scene quadrilateral and the center of projection can be analytically reconstructed from a single view when prior knowledge on the quadrilateral is available. A completely unknown quadrilateral can be reconstructed from four views through non-linear optimization. We also describe a improved method to handle an off-centered case by geometrically inferring a centered proxy quadrilateral, which accelerates a reconstruction process without relying on homography. The proposed method is easy to implement since each step is expressed as a simple analytic equation. We present the experimental results on real and synthetic examples.},
author = {Lee, Joo-Haeng},
booktitle = {2014 22nd International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2014.688},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee - 2014 - New Geometric Interpretation and Analytic Solution for Quadrilateral Reconstruction.pdf:pdf},
isbn = {978-1-4799-5209-0},
issn = {1051-4651},
keywords = {Cameras,Couplings,Equations,Image reconstruction,Mathematical model,Periodic structures,Vectors,generalized coupled line camera,geometric interpretation framework,geometry,image reconstruction,nonlinear optimization,optimisation,quadrilateral reconstruction,reconstruction process,scene quadrilateral,simple analytic equation},
month = {aug},
pages = {4015--4020},
publisher = {IEEE},
shorttitle = {Pattern Recognition (ICPR), 2014 22nd Internationa},
title = {{New Geometric Interpretation and Analytic Solution for Quadrilateral Reconstruction}},
year = {2014}
}
@inproceedings{Li2014,
abstract = {Unlike the traditional feature-based methods, we propose using motion vectors (MVs) from video streams as inputs for visual navigation. Although MVs are very noisy and with low spatial resolution, MVs do possess high temporal reso- lution which means it is possible to merge MVs from different frames to improve signal quality. Homography filtering and MV thresholding are proposed to further improve MV quality so that we can establish plane observations from MVs. We propose an extended Kalman filter (EKF) based approach to simultaneously track robot motion and planes. We formally model error propagation of MVs and derive variance of the merged MVs. We have implemented the proposed method and tested it in physical experiments. Results show that the system is capable of performing robot localization and plane mapping with a relative trajectory error of less than 5.1{\%}.},
author = {Li, Wen and Song, Dezhen},
booktitle = {IEEE Int. Conference on Robotics and Automation (ICRA)},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Song - 2014 - Toward featureless visual navigation simultaneous localization and planar surface extraction using motion vectors in.pdf:pdf},
isbn = {9781479936847},
keywords = {SLAM,optical flow,vision},
pages = {9--14},
title = {{Toward featureless visual navigation : simultaneous localization and planar surface extraction using motion vectors in video streams}},
year = {2014}
}
@article{Lu2015,
abstract = {We present a heterogeneous landmark-based visual navigation approach for a monocular mobile robot. We utilize heterogeneous visual features, such as points, line segments, lines, planes, and vanishing points, and their inner geometric constraints managed by a novel multilayer feature graph (MFG). Our method extends the local bundle adjustment-based visual simultaneous localization and mapping (SLAM) framework by explicitly exploiting the heterogeneous features and their inner geometric relationships in an unsupervised manner. As the result, our heterogeneous landmark-based visual navigation algorithm takes a video stream as input, initializes and iteratively updates MFG based on extracted key frames, and refines robot localization and MFG landmarks through the process. We present pseudocode for the algorithm and analyze its complexity. We have evaluated our method and compared it with state-of-the-art point landmark-based visual SLAM methods using multiple indoor and outdoor datasets. In particular, on the KITTI dataset, our method reduces the translational error by 52.5{\%} under urban sequences where rectilinear structures dominate the scene.},
author = {Lu, Yan and Song, Dezhen},
doi = {10.1109/TRO.2015.2424032},
file = {:home/a/Desktop/mfg.pdf:pdf},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Heterogeneous landmarks,simultaneous localization and mapping (SLAM),visual navigation)},
number = {3},
pages = {736--749},
title = {{Visual Navigation Using Heterogeneous Landmarks and Unsupervised Geometric Constraints}},
volume = {31},
year = {2015}
}
@inproceedings{Lu2014c,
author = {Lu, Yan and Song, Dezhen and Yi, Jingang},
booktitle = {IEEE Int. Conference on Robotics and Automation (ICRA)},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Song, Yi - 2014 - High Level Landmark-Based Visual Navigation Using Unsupervised Geometric Constraints in Local Bundle Adjustment.pdf:pdf},
isbn = {9781479936847},
keywords = {Computer Vision for Robotics and Automation,Localization,SLAM},
pages = {1540--1545},
title = {{High Level Landmark-Based Visual Navigation Using Unsupervised Geometric Constraints in Local Bundle Adjustment}},
year = {2014}
}
@inproceedings{Martinez2005,
abstract = {This paper presents an experimentally validated alternative to the classical extended Kalman filter approach to the solution of the probabilistic state-space simultaneous localization and mapping (SLAM) problem. Several authors have reported the divergence of this classical approach due to the linearization of the inherent nonlinear nature of the SLAM problem. Hence, the approach described in this work aims to avoid the analytical linearization based on Taylor-series expansion of both the model and measurement equations by using the unscented filter. An innovation-based consistency checking validates the feasibility and applicability of the unscented SLAM approach to a real large-scale outdoor exploration mission.},
author = {Martinez-Cantin, Ruben and Castellanos, Jos{\'{e}} A.},
booktitle = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
doi = {10.1109/IROS.2005.1545002},
isbn = {0780389123},
keywords = {Consistency,Normalized innovation squared test,SLAM,Unscented filtering},
pages = {328--333},
title = {{Unscented SLAM for large-scale outdoor environments}},
year = {2005}
}
@inproceedings{Wildenauer2008,
abstract = {We present a novel approach for detecting rectilinear structures and demonstrate their use for wide baseline stereo matching, planar 3D recon- struction, and computation of geometric context.},
author = {Mi{\v{c}}u{\v{s}}{\'{i}}k, Branislav and Wildenauer, Horst and Ko{\v{s}}eck{\'{a}}, Jana},
booktitle = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
doi = {10.1109/CVPR.2008.4587488},
isbn = {9781424422432},
issn = {1063-6919},
title = {{Detection and matching of rectilinear structures}},
year = {2008}
}
@article{Milford2008,
abstract = {This paper describes a biologically inspired approach to vision-only simultaneous localization and mapping (SLAM) on ground-based platforms. The core SLAM system, dubbed RatSLAM, is based on computational models of the rodent hip- pocampus, and is coupled with a lightweight vision system that provides odometry and appearance information. RatSLAM builds a map in an online manner, driving loop closure and relocaliza- tion through sequences of familiar visual scenes. Visual ambiguity is managed by maintaining multiple competing vehicle pose esti- mates,while cumulative errors in odometry are correctedafter loop closure by a map correction algorithm.We demonstrate the map- ping performance of the system on a 66 km car journey through a complex suburban road network. Using only a web camera oper- ating at 10 Hz, RatSLAM generates a coherent map of the entire environment at real-time speed, correctly closing more than 51 loops of up to 5 km in length.},
author = {Milford, Michael J and Wyeth, Gordon F},
doi = {10.1109/TRO.2008.2004520},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Milford, Wyeth - 2008 - Biologically Inspired SLAM System.pdf:pdf},
isbn = {1552-3098},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
number = {5},
pages = {1038--1053},
title = {{Biologically Inspired SLAM System}},
volume = {24},
year = {2008}
}
@inproceedings{Milford2012,
abstract = {Learning and then recognizing a route, whether travelled during the day or at night, in clear or inclement weather, and in summer or winter is a challenging task for state of the art algorithms in computer vision and robotics. In this paper, we present a new approach to visual navigation under changing conditions dubbed SeqSLAM. Instead of calculating the single location most likely given a current image, our approach calculates the best candidate matching location within every local navigation sequence. Localization is then achieved by recognizing coherent sequences of these “local best matches”. This approach removes the need for global matching performance by the vision front-end - instead it must only pick the best match within any short sequence of images. The approach is applicable over environment changes that render traditional feature-based techniques ineffective. Using two car-mounted camera datasets we demonstrate the effectiveness of the algorithm and compare it to one of the most successful feature-based SLAM algorithms, FAB-MAP. The perceptual change in the datasets is extreme; repeated traverses through environments during the day and then in the middle of the night, at times separated by months or years and in opposite seasons, and in clear weather and extremely heavy rain. While the feature-based method fails, the sequence-based algorithm is able to match trajectory segments at 100{\%} precision with recall rates of up to 60{\%}.},
author = {Milford, Michael J. and Wyeth, Gordon F.},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224623},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Milford, Wyeth - 2012 - SeqSLAM Visual route-based navigation for sunny summer days and stormy winter nights.pdf:pdf},
isbn = {9781467314039},
issn = {10504729},
pages = {1643--1649},
title = {{SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights}},
year = {2012}
}
@inproceedings{Montemerlo2002,
author = {Montemerlo, Michael and Thrun, Sebastian and Koller, Daphne and Wegbreit, Ben},
booktitle = {Proceedings of the National conference on Artificial Intelligence},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montemerlo et al. - Unknown - FastSLAM A Factored Solution to the Simultaneous Localization and Mapping Problem.pdf:pdf},
pages = {593--598},
publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
title = {{FastSLAM: A factored solution to the simultaneous localization and mapping problem}},
year = {2002}
}
@inproceedings{Newman2006,
abstract = {This paper describes a 3D SLAM system using information from an actuated laser scanner and camera installed on a mobile robot. The laser samples the local geometry of the environment and is used to incrementally build a 3D point-cloud map of the workspace. Sequences of images from the camera are used to detect loop closure events (without reference to the internal estimates of vehicle location) using a novel appearance-based retrieval system. The loop closure detection is robust to repetitive visual structure and provides a probabilistic measure of confidence. The images suggesting loop closure are then further processed with their corresponding local laser scans to yield putative Euclidean image-image transformations. We show how naive application of this transformation to effect the loop closure can lead to catastrophic linearization errors and go on to describe a way in which gross, pre-loop closing errors can be successfully annulled. We demonstrate our system working in a challenging, outdoor setting containing substantial loops and beguiling, gently curving traversals. The results are overlaid on an aerial image to provide a ground truth comparison with the estimated map. The paper concludes with an extension into the multi-robot domain in which 3D maps resulting from distinct SLAM sessions (no common reference frame) are combined without recourse to mutual observation},
author = {Newman, P. and Cole, D. and Ho, K.},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2006.1641869},
isbn = {0780395069},
issn = {10504729},
pages = {1180--1187},
title = {{Outdoor SLAM using visual appearance and laser ranging}},
volume = {2006},
year = {2006}
}
@article{Nister2005,
abstract = {A system capable of performing robust live ego-motion estimation for perspective cameras is presented. The system is powered by random sample consensus with preemptive scoring of the motion hypotheses. A general statement of the problem of efficient preemptive scoring is given. Then a theoretical investigation of preemptive scoring under a simple inlier-outlier model is performed. A practical preemption scheme is proposed and it is shown that the preemption is powerful enough to enable robust live structure and motion estimation.},
author = {Nist{\'{e}}r, David},
doi = {10.1007/s00138-005-0006-y},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nist{\'{e}}r - 2005 - Preemptive RANSAC for live structure and motion estimation.pdf:pdf},
isbn = {0-7695-1950-4},
issn = {09328092},
journal = {Machine Vision and Applications},
keywords = {3D-Reconstruction,Ego-motion,Real-time,Robust estimation,Structure from motion},
number = {5},
pages = {321--329},
title = {{Preemptive RANSAC for live structure and motion estimation}},
volume = {16},
year = {2005}
}
@article{Paz2008,
abstract = {In this paper, we describe a system that can carry out simultaneous localization and mapping (SLAM) in large indoor and outdoor environments using a stereo pair moving with 6 DOF as the only sensor. Unlike current visual SLAM systems that use either bearing-only monocular information or 3-D stereo information, our system accommodates both monocular and stereo. Textured point features are extracted from the images and stored as 3-D points if seen in both images with sufficient disparity, or stored as inverse depth points otherwise. This allows the system to map both near and far features: the first provide distance and orientation, and the second provide orientation information. Unlike other vision-only SLAM systems, stereo does not suffer from ldquoscale driftrdquo because of unobservability problems, and thus, no other information such as gyroscopes or accelerometers is required in our system. Our SLAM algorithm generates sequences of conditionally independent local maps that can share information related to the camera motion and common features being tracked. The system computes the full map using the novel conditionally independent divide and conquer algorithm, which allows constant time operation most of the time, with linear time updates to compute the full map. To demonstrate the robustness and scalability of our system, we show experimental results in indoor and outdoor urban environments of 210 m and 140 m loop trajectories, with the stereo camera being carried in hand by a person walking at normal walking speeds of 4--5 km/h.},
author = {Paz, Lina M. and Pini{\'{e}}s, Pedro and Tard{\'{o}}s, Juan D. and Neira, Jos{\'{e}}},
doi = {10.1109/TRO.2008.2004637},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paz et al. - 2008 - Large-scale 6-DOF SLAM with stereo-in-hand.pdf:pdf},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Linear time,Scalability,Stereo vision,Visual SLAM},
number = {5},
pages = {946--957},
title = {{Large-scale 6-DOF SLAM with stereo-in-hand}},
volume = {24},
year = {2008}
}
@inproceedings{Moreno2013,
abstract = {We present the major advantages of a new ‘object ori- ented' 3D SLAM paradigm, which takes full advantage in the loop of prior knowledge that many scenes consist of repeated, domain-specific objects and structures. As a hand-held depth camera browses a cluttered scene, real- time 3D object recognition and tracking provides 6DoF camera-object constraints which feed into an explicit graph of objects, continually refined by efficient pose-graph opti- misation. This offers the descriptive and predictive power of SLAM systems which perform dense surface reconstruc- tion, but with a huge representation compression. The ob- ject graph enables predictions for accurate ICP-based cam- era to model tracking at each live frame, and efficient ac- tive search for new objects in currently undescribed image regions. We demonstrate real-time incremental SLAM in large, cluttered environments, including loop closure, relo- calisation and the detection of moved objects, and of course the generation of an object level scene description with the potential to enable interaction.},
author = {Salas-Moreno, Renato F. and Newcombe, Richard A. and Strasdat, Hauke and Kelly, Paul H J and Davison, Andrew J.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.178},
file = {:home/a/Desktop/Salas-Moreno{\_}SLAM{\_}Simultaneous{\_}Localisation{\_}2013{\_}CVPR{\_}paper.pdf:pdf},
isbn = {978-0-7695-4989-7},
issn = {10636919},
keywords = {GPGPU,ICP,KinectFusion,SLAM,augmented reality,object recognition,object-oriented,objects,real-time,scene understanding},
pages = {1352--1359},
title = {{SLAM++: Simultaneous localisation and mapping at the level of objects}},
year = {2013}
}
@article{Schleicher2010,
abstract = {In this paper we present a new real-time hierarchical (topological/metric) Visual SLAM system focusing on the localization of a vehicle in large-scale outdoor urban environments. It is exclusively based on the visual information provided by a cheap wide-angle stereo camera. Our approach divides the whole map into local sub-maps identified by the so-called fingerprints (vehicle poses). At the sub-map level (low level SLAM), 3D sequential mapping of natural landmarks and the robot location/orientation are obtained using a top-down Bayesian method to model the dynamic behavior. A higher topological level (high level SLAM) based on fingerprints has been added to reduce the global accumulated drift, keeping real-time constraints. Using this hierarchical strategy, we keep the local consistency of the metric submaps, by mean of the EKF, and global consistency by using the topological map and the MultiLevel Relaxation (MLR) algorithm. Some experimental results for different large-scale outdoor environments are presented, showing an almost constant processing time. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Schleicher, David and Bergasa, Luis M. and Oca??a, Manuel and Barea, Rafael and L??pez, Elena},
doi = {10.1016/j.robot.2010.03.016},
isbn = {978-3-540-75866-2},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Mobile robots,Stereo vision,Tracking},
number = {8},
pages = {991--1002},
title = {{Real-time hierarchical stereo Visual SLAM in large-scale environments}},
volume = {58},
year = {2010}
}
@article{Se2005,
abstract = { We have previously developed a mobile robot system which uses scale-invariant visual landmarks to localize and simultaneously build three-dimensional (3-D) maps of unmodified environments. In this paper, we examine global localization, where the robot localizes itself globally, without any prior location estimate. This is achieved by matching distinctive visual landmarks in the current frame to a database map. A Hough transform approach and a RANSAC approach for global localization are compared, showing that RANSAC is much more efficient for matching specific features, but much worse for matching nonspecific features. Moreover, robust global localization can be achieved by matching a small submap of the local region built from multiple frames. This submap alignment algorithm for global localization can be applied to map building, which can be regarded as alignment of multiple 3-D submaps. A global minimization procedure is carried out using the loop closure constraint to avoid the effects of slippage and drift accumulation. Landmark uncertainty is taken into account in the submap alignment and the global minimization process. Experiments show that global localization can be achieved accurately using the scale-invariant landmarks. Our approach of pairwise submap alignment with backward correction in a consistent manner produces a better global 3-D map.},
author = {Se, S. and Lowe, D.G. and Little, J.J.},
doi = {10.1109/TRO.2004.839228},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Se, Lowe, Little - 2005 - Vision-based global localization and mapping for mobile robots.pdf:pdf},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
keywords = {Global localization,map building,mobile robots,visual landmarks},
number = {3},
pages = {364--375},
title = {{Vision-based global localization and mapping for mobile robots}},
volume = {21},
year = {2005}
}
@inproceedings{Strasdat2010,
abstract = {While the most accurate solution to off-line structure from motion (SFM) problems is undoubtedly to extract as much correspondence information as possible and perform global optimisation, sequential methods suitable for live video streams must approximate this to fit within fixed computational bounds. Two quite different approaches to real-time SFM - also called monocular SLAM (Simultaneous Localisation and Mapping) - have proven successful, but they sparsify the problem in different ways. Filtering methods marginalise out past poses and summarise the information gained over time with a probability distribution. Keyframe methods retain the optimisation approach of global bundle adjustment, but computationally must select only a small number of past frames to process. In this paper we perform the first rigorous analysis of the relative advantages of filtering and sparse optimisation for sequential monocular SLAM. A series of experiments in simulation as well using a real image SLAM system were performed by means of covariance propagation and Monte Carlo methods, and comparisons made using a combined cost/accuracy measure. With some well-discussed reservations, we conclude that while filtering may have a niche in systems with low processing resources, in most modern applications keyframe optimisation gives the most accuracy per unit of computing time.},
author = {Strasdat, Hauke and Montiel, J. M M and Davison, Andrew J.},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509636},
file = {:home/a/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strasdat, Montiel, Davison - 2010 - Real-time monocular SLAM Why filter.pdf:pdf},
isbn = {9781424450381},
issn = {10504729},
pages = {2657--2664},
pmid = {5509636},
title = {{Real-time monocular SLAM: Why filter?}},
year = {2010}
}
@article{Thrun2003,
abstract = {In this paper we describe a scalable algorithm for the simultaneous mapping and localization (SLAM) problem. SLAM is the problem of acquiring a map of a static environment with a mobile robot. The vast majority of SLAM algorithms are based on the extended Kalman filter (EKF). In this paper we advocate an algorithm that relies on the dual of the EKF, the extended information filter (EIF). We show that when represented in the information form, map posteriors are dominated by a small number of links that tie together nearby features in the map. This insight is developed into a sparse variant of the EIF, called the sparse extended information filter (SEIF). SEIFs represent maps by graphical networks of features that are locally interconnected, where links represent relative information between pairs of nearby features, as well as information about the robot's pose relative to the map. We show that all essential update equations in SEIFs can be executed in constant time, irrespective of the size of the map. We also provide empirical results obtained for a benchmark data set collected in an outdoor environment, and using a multi-robot mapping simulation.},
author = {Thrun, S and Liu, Y and Koller, D and Ng, Ay and Ghahramani, Z and Durrant-Whyte, H},
doi = {10.1177/0278364904045479},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
number = {7},
pages = {693--716},
pmid = {222793900003},
title = {{Simultaneous Localization and Mapping with Sparse Extended Information Filters}},
volume = {23},
year = {2003}
}
@article{Triggs2000,
abstract = {This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing pa- rameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares. Keywords:},
author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
doi = {10.1007/3-540-44480-7_21},
isbn = {3-540-67973-1},
issn = {978-3-540-67973-8},
journal = {Vision Algorithms: Theory and Practice},
keywords = {Bundle Adjustment,Gauge Freedom,Optimization,Scene Reconstruction,Sparse Matrices},
pages = {298--372},
title = {{Bundle Adjustment — A Modern Synthesis}},
volume = {1883},
year = {2000}
}
@article{Zhang2015,
abstract = {This paper presents a graph-based visual simultaneous localization and mapping (SLAM) system using straight lines as features. Compared with point features, lines provide far richer information about the structure of the environment and make it possible to infer spatial semantics from the map. Using a stereo rig as the sole sensor, our proposed system utilizes many advanced techniques, such as motion estimation, pose optimization, and bundle adjustment. We use two different representations to parameterize 3-D lines in this paper: Pl{\"{u}}cker line coordinates for efficient initialization of newly observed line features and projection of 3-D lines, and orthonormal representation for graph optimization. The proposed system is tested with indoor and outdoor sequences, and it exhibits better reconstruction performance against a point-based SLAM system in line-rich environments.},
author = {Zhang, Guoxuan and Lee, Jin Han and Lim, Jongwoo and Suh, Il Hong},
doi = {10.1109/TRO.2015.2489498},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Computer vision,Line feature,Mapping,Simultaneous localization and mapping (SLAM),Stereo},
number = {6},
pages = {1364--1377},
title = {{Building a 3-D line-based map using stereo SLAM}},
volume = {31},
year = {2015}
}
@inproceedings{Zhang2003,
abstract = {Man-made environments possess many regularities which can be efficiently exploited for image-based rendering as well as robotic navigation and localization tasks. In this paper, we present an approach for automatic extraction of dominant rectangular structures from a single view and show how they facilitate the recovery of camera pose, planar structure, and matching across widely separated views. In the presented approach, the rectangular hypothesis formation is based on a higher-level information encoded by the presence of orthogonal vanishing directions, the dominant rectangular structures can be detected and matched despite the presence of multiple repetitive structures often encountered in a variety of buildings. Different stages of the approach are demonstrated on various examples of images of indoor and outdoor structured environments. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {Zhang, Wei and Ko{\v{s}}eck{\'{a}}, J.},
booktitle = {Proceedings - 1st IEEE International Workshop on Higher-Level Knowledge in 3D Modeling and Motion Analysis, HLK 2003},
doi = {10.1109/HLK.2003.1240862},
isbn = {0769520499},
issn = {10773142},
keywords = {Buildings,Cameras,Computer science,Data mining,Humans,Navigation,Rendering (computer graphics),Robot vision systems,Robotics and automation,Solid modeling},
pages = {83--91},
title = {{Extraction, matching and pose recovery based on dominant rectangular structures}},
year = {2003}
}
